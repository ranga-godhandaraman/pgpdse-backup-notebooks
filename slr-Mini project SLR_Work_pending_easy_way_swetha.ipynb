{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e18acb0",
   "metadata": {},
   "source": [
    "# Step 1: Understand the business problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa24aa03",
   "metadata": {},
   "source": [
    "1. URL - Website of the Zomato for each restaurant. - Object datatype\n",
    "2. Address - Address of the Restaurant. - Object datatype\n",
    "3. Name - Name of the restaurant. - Object datatype\n",
    "4. Online Order - The customer ordered the menu online or not. - Object datatype\n",
    "5. Book table - The customer has booked the table or not. - Object datatype\n",
    "6. Rate - Rating of the restaurant that has by the customer. - Numerical datatype\n",
    "7. Votes - The votes have been given by the customer to the restaurant. - Numerical \n",
    "datatype\n",
    "8. Phone - Contact number of the Restaurant. - Object datatype\n",
    "9. Location - The city name where the restaurant is located. - Object datatype\n",
    "10. Rest Type - The type of restaurant. - Object datatype\n",
    "11. Dish liked - Dishes liked by the customer from the restaurant. - Object datatype\n",
    "12. Cuisines - The cuisines that have been prepared by the restaurant. - Object datatype\n",
    "13. Approx Cost for two people - The approximate cost of the customer for 2 people. -\n",
    "Number datatype\n",
    "14. Reviews list - The reviews made by the customers on the restaurant. - Object \n",
    "datatype\n",
    "15. Menu Item - The menu items that are usually available at the restaurant. - Object \n",
    "datatype\n",
    "16. Listed in (type) - Contains the type of the meal. - Object datatype\n",
    "17. Listed in (city) - This contains the neighborhood in which the restaurant is listed. -\n",
    "Object datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05695f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c476a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04576f6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 49>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# import function to perform GridSearchCV\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlxtend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SequentialFeatureSelector \u001b[38;5;28;01mas\u001b[39;00m sfs\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# display all columns of the dataframe\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# display all rows of the dataframe\n",
    "pd.options.display.max_rows = None\n",
    " \n",
    "# to display the float values upto 6 decimal places     \n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# import StandardScaler to perform scaling\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# import SGDRegressor from sklearn to perform linear regression with stochastic gradient descent\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# import function for ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# import function for lasso regression\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# import function for elastic net regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# import function to perform GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f231f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf59e6",
   "metadata": {},
   "source": [
    "# step 2: Read the data, and convert the data types.\n",
    "Note: The data set has numerical and categorical data but due to noise(anomaly) in \n",
    "the data, the columns are treated as the object type. And You may feel like converting the \n",
    "features into numerical at this step if not appropriate at this stage, In that case, feel free to \n",
    "convert the variable to the appropriate type in the further step as well based on your way \n",
    "of analyzing the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436aa5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato_orgnl=pd.read_csv('zomato.csv')\n",
    "zomato_orgnl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bd3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato_orgnl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato_orgnl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa12eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato=zomato_orgnl.drop(['url','dish_liked','phone','phone'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b12a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the Columns Names\n",
    "zomato_orgnl.columns\n",
    "zomato = zomato.rename(columns={'approx_cost(for two people)':'cost','listed_in(type)':'type','listed_in(city)':'city'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0215188c",
   "metadata": {},
   "source": [
    "# Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5153bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato['cost'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc240947",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zomato['cost'] = zomato['cost'].astype(str)\n",
    "zomato['cost'] = zomato['cost'].apply(lambda x: x.replace(',','.'))\n",
    "zomato['cost'] = zomato['cost'].astype(float)\n",
    "zomato.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading uninque values from the Rate column\n",
    "zomato['rate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6cce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato['rate'].unique()\n",
    "zomato = zomato.loc[zomato.rate !='NEW']\n",
    "zomato = zomato.loc[zomato.rate !='-'].reset_index(drop=True)\n",
    "\n",
    "remove_slash = lambda x: x.replace('/5', '') if type(x) == np.str else x\n",
    "zomato.rate = zomato.rate.apply(remove_slash).str.strip().astype('float')\n",
    "zomato['rate'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1170f4a6",
   "metadata": {},
   "source": [
    "Step 3: Perform the described method for the data, Try to find any essential points from the \n",
    "described analysis. And check the missing values and Duplicate records. Impute the \n",
    "missing values in the best way possible.\n",
    "Note: To impute the missing values with parameters, You must find the best parameter.\n",
    "Hints:\n",
    "‚óè Check the distribution using plots. And check the Skewness, Kurtosis and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e53a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15a92c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato.describe(include=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf3b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad61ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato.isnull().sum()/zomato.isnull().count()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e18be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato['rate'].fillna(zomato['rate'].mode()[0],inplace=True)\n",
    "zomato['rest_type'].fillna(zomato['rest_type'].mode()[0],inplace=True)\n",
    "zomato['cost'].fillna(zomato['cost'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7227114c",
   "metadata": {},
   "source": [
    "# Drop null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd13363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the NaN values from the dataset\n",
    "zomato.dropna(how='any',inplace=True)\n",
    "zomato.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a3197",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num=zomato.select_dtypes(include=np.number)\n",
    "df_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bdddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=1\n",
    "plt.figure(figsize=(15,10))\n",
    "for i in df_num:\n",
    "    plt.subplot(2,2,t)\n",
    "    sns.distplot(zomato[i])\n",
    "    plt.xticks(rotation=90)\n",
    "    t+=1\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98243cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the Duplicates\n",
    "zomato.duplicated().sum()\n",
    "zomato.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514cb72f",
   "metadata": {},
   "source": [
    "# Step 4: Once the basic preprocessing is done like converting the data types, missing value  imputation, and duplicate rows. perform the EDA(Exploratory Data Analysis) on the data to  find the various factors that will help to understand the cost per two persons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b51f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat=zomato.select_dtypes(include=object)\n",
    "df_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe80c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(zomato['online_order'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,10)\n",
    "plt.title('Restaurants delivering online or Not')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c9eb5",
   "metadata": {},
   "source": [
    "# How many restaurants are present at different city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c0b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato.city.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a03729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot of city\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.countplot(x='city', data=zomato)\n",
    "plt.title('Count of Restaurants at each Location', fontsize=20, fontweight='bold')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0078404c",
   "metadata": {},
   "source": [
    "There are more than 3000 restaurants in BTM. Quick Google Search shows us that BTM is posh residential area so because of that there are quite a lot of restaurants and also it is famous for cafes. JP Nagar HSR, Koramangala 5th block, Whitefield, Indiranagar have more than 2000 restaurants and Jayanagar, Marathahalli, Bannerghatta Road have more than 1000 restaurants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0506b8",
   "metadata": {},
   "source": [
    "# Restaurant types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e0be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of rest_type\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.countplot(x='rest_type', data=zomato)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Count of each restaurant type', fontsize=20, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383bc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "chains = zomato['name'].value_counts()[:20]\n",
    "sns.barplot(x=chains, y=chains.index, palette='Set1')\n",
    "plt.xlabel(\"Number of outlets\", size=15)\n",
    "plt.ylabel(\"Name of Restaurants\", size=15)\n",
    "plt.title(\"Most famous restaurant chains\", fontsize=20, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abba57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cafe Coffee Day has maximum outlets in the city and is followed by Onesta with number of outlets little more than 80. It can be seen that most famous restaurant chains have more than 50 outlets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a766a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_online_booking = zomato.groupby([\"online_order\", \"book_table\"]).size().reset_index(name = \"Count\")\n",
    "plt.figure(figsize = (15,7))\n",
    "sns.barplot(x=\"online_order\", y=\"Count\", hue=\"book_table\", data=df_online_booking)\n",
    "plt.title(\"Online Order - Book Table\", fontsize=20, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb8674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = [\"Accepted\",'Not Accepted']\n",
    "label2 = ['Not Accepted', \"Accepted\"]\n",
    "\n",
    "df_online = zomato['online_order'].value_counts().values\n",
    "df_table = zomato['book_table'].value_counts().values\n",
    "\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "color1 = ['#FA744F', '#16817A']\n",
    "color2 = ['#FC5050', '#FFD00C']\n",
    "\n",
    "ax1[0].pie(df_online, labels=label1, autopct='%1.1f%%', startangle=90, colors=color1)\n",
    "ax1[0].set_title('Online order', fontsize=20, fontweight='bold')\n",
    "\n",
    "ax1[1].pie(df_table, labels=label2, autopct='%1.1f%%', startangle=90, colors=color2)\n",
    "ax1[1].set_title('Book table', fontsize=20, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5626946",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (13, 9)\n",
    "Y = pd.crosstab(zomato['rate'], zomato['book_table'])\n",
    "Y.div(Y.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked = True,color=['red','yellow'])\n",
    "plt.title('table booking vs rate', fontweight = 30, fontsize = 20)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(zomato['city'])\n",
    "sns.countplot(zomato['city']).set_xticklabels(sns.countplot(zomato['city']).get_xticklabels(), rotation=90, ha=\"right\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(13,13)\n",
    "plt.title('Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423cc8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_plt=pd.crosstab(zomato['rate'],zomato['city'])\n",
    "loc_plt.plot(kind='bar',stacked=True);\n",
    "plt.title('Location - Rating',fontsize=15,fontweight='bold')\n",
    "plt.ylabel('Location',fontsize=10,fontweight='bold')\n",
    "plt.xlabel('Rating',fontsize=10,fontweight='bold')\n",
    "plt.xticks(fontsize=10,fontweight='bold')\n",
    "plt.yticks(fontsize=10,fontweight='bold');\n",
    "plt.legend().remove();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dbf343",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6)) \n",
    "zomato_orgnl['location'].value_counts()[:10].plot(kind = 'pie')\n",
    "plt.title('Location', weight = 'bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcade2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,6))\n",
    "names = zomato_orgnl['location'].value_counts()[:10].index\n",
    "values = zomato_orgnl['location'].value_counts()[:10].values\n",
    "colors = ['gold', 'red', 'lightcoral', 'lightskyblue','blue','green','silver']\n",
    "explode = (0.1, 0, 0, 0,0,0,0,0,0,0)  # explode 1st slice\n",
    "\n",
    "plt.pie(values, explode=explode, labels=names, colors=colors,autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.title(\"Percentage of restaurants present in that location\", weight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3c7cc7",
   "metadata": {},
   "source": [
    "# Distribution of Cost of Food for two People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6855e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zomato.menu_item = np.where(zomato.menu_item == '[]',zomato.menu_item.value_counts().index[1],zomato.menu_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7980f0e7",
   "metadata": {},
   "source": [
    "# Step 5: Make a copy of the data set and Perform the preprocessing that require for the  model.Note: You can see many categorical variables with a high number of unique values. Therefore do not keep dropping the variables as the first option, try to create new variables  or perform any other feature engineering methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f97398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zomato=zomato.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c0ee40",
   "metadata": {},
   "source": [
    "#  Convert the online categorical variables into a numeric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d165d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato.online_order[zomato.online_order == 'Yes'] = 1 \n",
    "zomato.online_order[zomato.online_order == 'No'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b027b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato.online_order.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4201f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato.online_order = pd.to_numeric(zomato.online_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd9d3c6",
   "metadata": {},
   "source": [
    "# change the string categorical into to a categorical int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c68652",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato.book_table[zomato.book_table == 'Yes'] = 1 \n",
    "zomato.book_table[zomato.book_table == 'No'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a7237",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato.book_table = pd.to_numeric(zomato.book_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74edb580",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato.book_table.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a117fa56",
   "metadata": {},
   "source": [
    "# Label encode the categorical variables to make it easier to build algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268514bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b531a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato.location = le.fit_transform(zomato.location)\n",
    "zomato.rest_type = le.fit_transform(zomato.rest_type)\n",
    "zomato.cuisines = le.fit_transform(zomato.cuisines)\n",
    "zomato.menu_item = le.fit_transform(zomato.menu_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506cebdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d62696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #def Encode(zomato):\n",
    "#     for column in zomato.columns[~zomato.columns.isin(['rate', 'cost', 'votes'])]:\n",
    "#         zomato[column] = zomato[column].factorize()[0]\n",
    "#     return zomato\n",
    "\n",
    "# zomato_en = Encode(zomato.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zomato['Number_of_cuisines_offered'] = zomato['cuisines'].apply(lambda x : len(x.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d545f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_numerical=zomato.select_dtypes(include=np.number)\n",
    "#df_categorical=zomato.select_dtypes(include=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1bd2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_numerical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357955f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_categorical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64cd498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#X_scaler = MinMaxScaler()\n",
    "\n",
    "#num_scaled = X_scaler.fit_transform(df_numerical)\n",
    "\n",
    "#df_num_scaled = pd.DataFrame(num_scaled, columns = df_numerical.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249ced84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df_categorical.city.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dummy=pd.get_dummies(data=df_categorical,columns=['book_table','online_order','type'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b1b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dummy['cuisines']=df_dummy['cuisines'].replace(df_dummy.cuisines.value_counts(1))\n",
    "#df_dummy['name']=df_dummy['name'].replace(df_dummy.name.value_counts(1))\n",
    "#df_dummy['rest_type']=df_dummy['rest_type'].replace(df_dummy.rest_type.value_counts(1))\n",
    "#df_dummy['city']=df_dummy['city'].replace(df_dummy.city.value_counts(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be79a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zomato = pd.concat([df_num_scaled,df_dummy], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3371ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zomato.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ddc995",
   "metadata": {},
   "source": [
    "# Step 6: Perform statistical hypothesis testing on features to get an idea of whether features are impacting the target variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482c78c6",
   "metadata": {},
   "source": [
    "Dividing the dataset into categorical and numerical columns and then finding pvalue for each independent feature corresponding to dependent feture(cost). Keeping pvalue threshold as 0.05\n",
    "\n",
    "1. Hypothesis Testing for Categorical columns and stroke\n",
    "\n",
    "Hypothesis :\n",
    "\n",
    "H0:Independent variables are not significantly associated with the dependent variable (cost)\n",
    "\n",
    "H1:Independent variables are significantly associated with the dependent variable (cost)\n",
    "\n",
    "if pvalue<0.05 we will reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c21475",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['name', 'online_order', 'book_table', 'rest_type', 'cuisines','reviews_list', 'type', 'city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17e32cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To perform hypothesis between categorical columns we are using chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "673fd5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "pvalue_score = pd.DataFrame(columns=['Feature','pvalue'])\n",
    "\n",
    "\n",
    "def update_score_categorical(cat_cols):\n",
    "    \n",
    "    global pvalue_score\n",
    "    for col in cat_cols:\n",
    "        contingency_table = pd.crosstab(zomato[col], zomato['cost'])\n",
    "        chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "        pvalue_score = pvalue_score.append({'Feature':col,'pvalue':p_value}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "337f372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of categorical variables\n",
    "cat_cols = ['name', 'online_order', 'book_table', 'rest_type', 'cuisines','reviews_list', 'type', 'city']\n",
    "update_score_categorical(cat_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89644192",
   "metadata": {},
   "source": [
    "2. Hypothesis Testing for numerical columns and stroke\n",
    "\n",
    "Hypothesis :\n",
    "\n",
    "H0:The variables are not correlated with each other\n",
    "\n",
    "H1:The variables are correlated with each other\n",
    "\n",
    "if pvalue<0.05 we will reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a1737e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>pvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>online_order</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book_table</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rest_type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cuisines</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reviews_list</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>type</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>city</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature   pvalue\n",
       "0          name 0.000000\n",
       "1  online_order 0.000000\n",
       "2    book_table 0.000000\n",
       "3     rest_type 0.000000\n",
       "4      cuisines 0.000000\n",
       "5  reviews_list 0.000000\n",
       "6          type 0.000000\n",
       "7          city 0.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b544b9d",
   "metadata": {},
   "source": [
    "# Step 7: Split the dataset into train and test data sets and Perform the scaling on both sets if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f571264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44496, 8)\n",
      "(44496,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x = zomato.iloc[:,[2,3,4,5,6,7,8,11]]\n",
    "y = zomato['cost']\n",
    "#Getting Test and Training Set\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.1,random_state=353)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d89510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split \n",
    "# x = zomato_en.iloc[:,[2,3,4,5,6,7,8,11,12]]\n",
    "# y = zomato_en['cost']\n",
    "# #Getting Test and Training Set\n",
    "# x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.1,random_state=353)\n",
    "# x_train.head()\n",
    "# y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2411b9e",
   "metadata": {},
   "source": [
    "# Step 8: Build the base model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d4884",
   "metadata": {},
   "source": [
    "# LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ce5829a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Yes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m lin_reg\u001b[38;5;241m=\u001b[39mLinearRegression()\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mlin_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m ypred\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m      4\u001b[0m rmse\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_test,ypred))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:662\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    658\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    660\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 662\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    664\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    667\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Yes'"
     ]
    }
   ],
   "source": [
    "lin_reg=LinearRegression()\n",
    "model=lin_reg.fit(x_train,y_train)\n",
    "ypred=model.predict(x_test)\n",
    "rmse=np.sqrt(mean_squared_error(y_test,ypred))\n",
    "print(rmse)\n",
    "from sklearn.metrics import r2_score\n",
    "r2=r2_score(y_test,ypred)\n",
    "print(r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a441ba7",
   "metadata": {},
   "source": [
    "# Descision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d131b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.1,random_state=105)\n",
    "Dtree=DecisionTreeRegressor(min_samples_leaf=.0001)\n",
    "Dtree.fit(x_train,y_train)\n",
    "y_predict=Dtree.predict(x_test)\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b28e53",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c64c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "Rforest=RandomForestRegressor(n_estimators=500,random_state=10,min_samples_leaf=.0001)\n",
    "Rforest.fit(x_train,y_train)\n",
    "y_predict=Rforest.predict(x_test)\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec081974",
   "metadata": {},
   "outputs": [],
   "source": [
    "Randpred =pd.DataFrame({ \"actual\": y_test, \"pred\": y_predict })\n",
    "Randpred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b3f45",
   "metadata": {},
   "source": [
    "# Step 9: Understand how the model is performing, Perform feature engineering again if needed. Do feature selection. Try with various models like a parametric and nonparametric models. Once you choose the final model, rebuild the model with best parameters. Note: If you are performing with Linear models, check the model is fulfilling the assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_rmse(model): \n",
    "    train_pred = model.predict(x_train)\n",
    "    mse_train = mean_squared_error(y_train, train_pred)\n",
    "    rmse_train = round(np.sqrt(mse_train), 4)\n",
    "    return(rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e5408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_rmse(model):\n",
    "    test_pred = model.predict(x_test)\n",
    "    mse_test = mean_squared_error(y_test, test_pred)\n",
    "    rmse_test = round(np.sqrt(mse_test), 4)\n",
    "    return(rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf7aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(actual, predicted):\n",
    "    return (np.mean(np.abs((actual - predicted) / actual)) * 100)\n",
    "def get_test_mape(model):\n",
    "    test_pred = model.predict(x_test)\n",
    "    mape_test = mape(y_test, test_pred)\n",
    "    return(mape_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd97899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model):\n",
    "    r_sq = model.score(x_train, y_train)\n",
    "    n = x_train.shape[0]\n",
    "    k = x_train.shape[1]\n",
    "    r_sq_adj = 1 - ((1-r_sq)*(n-1)/(n-k-1))\n",
    "    return ([r_sq, r_sq_adj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4410ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_card = pd.DataFrame(columns=['Model_Name', 'Alpha (Wherever Required)', 'l1-ratio', 'R-Squared',\n",
    "                                       'Adj. R-Squared', 'Test_RMSE', 'Test_MAPE'])\n",
    "def update_score_card(algorithm_name, model, alpha = '-', l1_ratio = '-'):\n",
    "    global score_card\n",
    "    score_card = score_card.append({'Model_Name': algorithm_name,\n",
    "                       'Alpha (Wherever Required)': alpha, \n",
    "                       'l1-ratio': l1_ratio, \n",
    "                       'Test_MAPE': get_test_mape(model), \n",
    "                       'Test_RMSE': get_test_rmse(model), \n",
    "                       'R-Squared': get_score(model)[0], \n",
    "                       'Adj. R-Squared': get_score(model)[1]}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37940c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDRegressor(random_state = 10)\n",
    "linreg_with_SGD = sgd.fit(x_train, y_train)\n",
    "print('RMSE on train set:', get_train_rmse(linreg_with_SGD))\n",
    "print('RMSE on test set:', get_test_rmse(linreg_with_SGD)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ee122",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_score_card(algorithm_name = 'Linear Regression (using SGD)', model = linreg_with_SGD)\n",
    "score_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0dfb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha = 1, max_iter = 500)\n",
    "ridge.fit(x_train, y_train)\n",
    "print('RMSE on test set:', get_test_rmse(ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_score_card(algorithm_name='Ridge Regression (with alpha = 1)', model = ridge, alpha = 1)\n",
    "score_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca816f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha = 2, max_iter = 500)\n",
    "ridge.fit(x_train, y_train)\n",
    "print('RMSE on test set:', get_test_rmse(ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe6976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_score_card(algorithm_name = 'Ridge Regression (with alpha = 2)', model = ridge, alpha = '2')\n",
    "score_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a621b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha = 0.01, max_iter = 500)\n",
    "lasso.fit(x_train, y_train)\n",
    "print('RMSE on test set:', get_test_rmse(lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb11dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_score_card(algorithm_name = 'Lasso Regression', model = lasso, alpha = '0.01')\n",
    "score_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d6ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "enet = ElasticNet(alpha = 0.1, l1_ratio = 0.01, max_iter = 500)\n",
    "enet.fit(x_train, y_train)\n",
    "print('RMSE on test set:', get_test_rmse(enet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184aff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_score_card(algorithm_name = 'Elastic Net Regression', model = enet, alpha = '0.1', l1_ratio = '0.01')\n",
    "score_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5badd8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_paramaters = [{'alpha':[1e-15, 1e-10, 1e-8, 1e-4,1e-3, 1e-2, 0.1, 1, 5, 10, 20, 40, 60, 80, 100]}]\n",
    "ridge = Ridge()\n",
    "ridge_grid = GridSearchCV(estimator = ridge, \n",
    "                          param_grid = tuned_paramaters, \n",
    "                          cv = 10)\n",
    "ridge_grid.fit(x_train, y_train)\n",
    "print('Best parameters for Ridge Regression: ', ridge_grid.best_params_, '\\n')\n",
    "print('RMSE on test set:', get_test_rmse(ridge_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe7844",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_score_card(algorithm_name = 'Ridge Regression (using GridSearchCV)', \n",
    "                  model = ridge_grid, \n",
    "                  alpha = ridge_grid.best_params_.get('alpha'))\n",
    "score_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "tuned_paramaters = [{'alpha':[1e-15, 1e-10, 1e-8, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10, 20]}]\n",
    "lasso = Lasso()\n",
    "lasso_grid = GridSearchCV(estimator = lasso, \n",
    "                          param_grid = tuned_paramaters, \n",
    "                          cv = cv)\n",
    "lasso_grid.fit(x_train, y_train)\n",
    "print('Best parameters for Lasso Regression: ', lasso_grid.best_params_, '\\n')\n",
    "print('RMSE on test set:', get_test_rmse(lasso_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6520569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_score_card(algorithm_name = 'Lasso Regression (using GridSearchCV)', \n",
    "                  model = lasso_grid, \n",
    "                  alpha = lasso_grid.best_params_.get('alpha'))\n",
    "score_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c631b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_paramaters = [{'alpha':[0.0001, 0.001, 0.01, 0.1, 1, 5, 10, 20, 40, 60],\n",
    "                      'l1_ratio':[0.0001, 0.0002, 0.001, 0.01, 0.1, 0.2]}] \n",
    "enet = ElasticNet()\n",
    "enet_grid = GridSearchCV(estimator = enet, \n",
    "                          param_grid = tuned_paramaters, \n",
    "                          cv = 10)\n",
    "enet_grid.fit(x_train, y_train)\n",
    "print('Best parameters for Elastic Net Regression: ', enet_grid.best_params_, '\\n')\n",
    "print('RMSE on test set:', get_test_rmse(enet_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28627a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_score_card(algorithm_name = 'Elastic Net Regression (using GridSearchCV)', \n",
    "                  model = enet_grid, \n",
    "                  alpha = enet_grid.best_params_.get('alpha'), \n",
    "                  l1_ratio = enet_grid.best_params_.get('l1_ratio'))\n",
    "score_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d43f806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_card = score_card.sort_values('Test_RMSE').reset_index(drop = True)\n",
    "score_card.style.highlight_min(color = 'lightblue', subset = 'Test_RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7142f3cf",
   "metadata": {},
   "source": [
    "We can see that Lasso Regression (using GridSearchCV) has the lowest test RMSE ans test MAPE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha = 0.0000000000000001, max_iter = 500)\n",
    "# lasso.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aaac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_forward = sfs(estimator = lasso, k_features = 'best', forward = True,\n",
    "                     verbose = 2, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db29ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = lasso_forward.fit(x_train, y_train)\n",
    "# print('RMSE on test set:', get_test_rmse(lasso_forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5888c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the selected feature names when k_features = 12\n",
    "print('Features selelected using forward selection are: ')\n",
    "print(abc.k_feature_names_)\n",
    "\n",
    "# print the R-squared value\n",
    "print('\\nR-Squared: ', abc.k_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f971e4",
   "metadata": {},
   "source": [
    "# Step 10: Based on your understanding of the model and EDA analysis, Explain the business understanding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ee4000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f7a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "lasso = Lasso()\n",
    "selector = SelectFromModel(lasso)\n",
    "selector.fit_transform(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c96213",
   "metadata": {},
   "outputs": [],
   "source": [
    "    param_grid = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "    grid = GridSearchCV(Lasso(), param_grid=param_grid, cv=5)\n",
    "    grid.fit(x_train, y_train)\n",
    "    alpha = grid.best_params_['alpha']\n",
    "\n",
    "    # Train the Lasso regression model with the optimal hyperparameters\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(x_train, y_train)\n",
    "\n",
    "    # Calculate the R-squared value for the model\n",
    "    r_squared = lasso.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98097c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c21225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662482ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a7d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4053822f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
